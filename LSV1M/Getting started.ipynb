{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec4ac57",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a27d2",
   "metadata": {},
   "source": [
    "## Mozaik\n",
    "\n",
    "Read the [Mozaik README](https://github.com/CSNG-MFF/mozaik) for installation and how to run Mozaik experiments locally on your computer.\n",
    "\n",
    "## Running experiments through Slurm\n",
    "To run the model through Slurm (which we use to schedule jobs on the cluster), run:\n",
    "\n",
    "`python run_model_slurm.py run.py nest param/defaults`\n",
    "\n",
    "You can see the jobs currently running on the cluster with `squeue`, summarized info about jobs with `sinfo`, and cancel your jobs with `scancel job_id` (e.g. `scancel 237444`). Naturally, you can only cancel your own jobs. \n",
    "\n",
    "The script `run_model_slurm.py` has several useful options for setting up the Slurm job to run the experiment. I mostly only change the job name, and the `--exclude` parameter, where you can specify where your job should not run. If you know you'll be running a job that takes a long time (4h+), please schedule it such that you'll leave a node or so empty, unless it's the evening or the weekend.\n",
    "\n",
    "## Modifying the experiments\n",
    "\n",
    "You can modify the basic runscript in `run.py`, and the experiment parameters in `experiments.py`. \n",
    "\n",
    "At first, try to limit your run to only a few images! Because of the structure of the Mozaik framework, all the numpy arrays with the optogenetic stimulation data are generated before any experiment is run, and thus the runs can be quite memory intensive.\n",
    "\n",
    "## Changing model parameters\n",
    "\n",
    "If you'll need to, you can change the model parameters dynamically in the `run_model_slurm.py` file. As an example, you can do:\n",
    "```\n",
    "CombinationParameterSearch(\n",
    "    SlurmSequentialBackend(\n",
    "        num_threads=16,\n",
    "        num_mpi=1,\n",
    "        path_to_mozaik_env=\"/home/rozsa/virt_env/mozaik/bin/activate\",\n",
    "        slurm_options=slurm_options,\n",
    "    ),  \n",
    "    {   \n",
    "        'pynn_seed': [520,1024,2240],\n",
    "    },\n",
    ").run_parameter_search()\n",
    "```\n",
    "\n",
    "Then the model will run 3x in parallel with the same experiment, but with different random seeds. To access nested parameters, use this notation: `'sheets.l4_cortex_exc.params.cell.params.tau_m': [8,9]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ce28d",
   "metadata": {},
   "source": [
    "# Viewing experiment results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff5fe5",
   "metadata": {},
   "source": [
    "## Results folder\n",
    "The results are stored in folder with following the naming format:\n",
    "\n",
    "```\n",
    "datetime[parameter_dir_name]CombinationParamSearch{parameter_names_and_values}/\n",
    "modelname_ParameterSearch_____paramname1:paramvalue_paramname2:paramvalue\n",
    "```\n",
    "\n",
    "For example: \n",
    "```\n",
    "20230131-135335[param.defaults]CombinationParamSearch{trial:[1]}/\n",
    "SelfSustainedPushPull_ParameterSearch_____trial:1\n",
    "```\n",
    "\n",
    "## Run log\n",
    "\n",
    "The log file of the run is stored in the main result folder under the name `slurm_jobid.out`:\n",
    "\n",
    "`20230131-135335[param.defaults]CombinationParamSearch{trial:[1]}/slurm_237566.out`\n",
    "\n",
    "This will contain all logging messages from the run, as well as any errors that happened during it. If your run is successful, the end of your log file should look something like this:\n",
    "\n",
    "```\n",
    "0    Stimulus 1/1 finished. Memory usage: 12825MB\n",
    "0    Experiment 1/1 finished\n",
    "0    Total simulation run time: 118s\n",
    "0    Simulator run time: 73s (62%) \n",
    "0    Mozaik run time: 44s (37%) \n",
    "```\n",
    "\n",
    "## Reading experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a76a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mozaik.storage.datastore import PickledDataStore\n",
    "from parameters import ParameterSet\n",
    "from mozaik.storage.queries import param_filter_query\n",
    "from mozaik.tools.distribution_parametrization import load_parameters\n",
    "import logging\n",
    "import sys\n",
    "from mozaik.storage.queries import *\n",
    "from mozaik.analysis.analysis import *\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "from mozaik.storage.datastore import DataStoreView\n",
    "\n",
    "# Path to the experiment DataStore\n",
    "# Substitute this path with the path of your own run!\n",
    "#path = \"20230203-174506[param.defaults]CombinationParamSearch{trial:[1]}/SelfSustainedPushPull_ParameterSearch_____trial:1\"\n",
    "path = \"SelfSustainedPushPull_ParameterSearch_____base_weight:0.00026_base_weight:0.0016_tau_rec:100_sigma:1.3_base_weight:0.00022_AfferentMean:42/\"\n",
    "\n",
    "data_store = PickledDataStore(\n",
    "    load=True,\n",
    "    parameters=ParameterSet({\"root_directory\": path, \"store_stimuli\": False}),\n",
    "    replace=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Mozaik:Starting PSTH analysis\n"
     ]
    }
   ],
   "source": [
    "# Some example analysis\n",
    "PSTH(data_store,ParameterSet({'bin_length': 20.0})).analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f568c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "excitatory_cortical_layers = [\"V1_Exc_L4\",\"V1_Exc_L2/3\"]\n",
    "\n",
    "# Some example analysis and plots\n",
    "for sheet in excitatory_cortical_layers:\n",
    "    # We can query the DataStore for the results we want\n",
    "    # It returns a DataStoreView, a slice of the DataStore\n",
    "    dsv = param_filter_query(data_store, st_name=\"NaturalImageWithEyeMovement\", sheet_name=sheet)\n",
    "    dsv.print_content()\n",
    "    print(\"Example of a single stimulus:\",dsv.get_stimuli()[0])\n",
    "    \n",
    "    # Retrieve spike times for all neurons for a particular stimulus presentation\n",
    "    \n",
    "    # Retrieve PSTH analysis results\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_ids(dsv):\n",
    "    assert len(dsv.sheets()) == 1\n",
    "    return [s for s in dsv.get_segments() if len(s.spiketrains) > 0][0].get_stored_spike_train_ids()\n",
    "\n",
    "def get_s(dsv, s_res=None):\n",
    "    \"\"\"\n",
    "    Retrieve positions for all neurons in DataStoreView\n",
    "    \"\"\"\n",
    "    if s_res == None:\n",
    "        s_res = 1\n",
    "    st_ids = get_st_ids(dsv)\n",
    "    sheet = dsv.sheets()[0]\n",
    "    pos = dsv.get_neuron_positions()[sheet]\n",
    "    posx = (pos[0, dsv.get_sheet_indexes(sheet, st_ids)] / s_res * 1000).astype(int)\n",
    "    posy = (pos[1, dsv.get_sheet_indexes(sheet, st_ids)] / s_res * 1000).astype(int)\n",
    "    posx -= min(posx)\n",
    "    posy -= min(posy)\n",
    "    return posx, posy\n",
    "\n",
    "def get_t(dsv, t_res=None):\n",
    "    \"\"\"\n",
    "    Retrieve spike times for all neurons in DataStoreView\n",
    "    \"\"\"\n",
    "    if t_res == None:\n",
    "        t_res = 1\n",
    "    st_ids = get_st_ids(dsv)\n",
    "    segs = [s for s in dsv.get_segments() if len(s.spiketrains) > 0]\n",
    "    t = [[] for i in range(len(st_ids))]\n",
    "    time_passed = 0\n",
    "    for i in range(len(segs)):\n",
    "        if len(segs[i].spiketrains) == 0:\n",
    "            continue\n",
    "        sts = segs[i].get_spiketrains()\n",
    "        for j in range(len(sts)): \n",
    "            t[j].extend(list((sts[j].magnitude / t_res).astype(int) + time_passed))\n",
    "        time_passed += int((sts[0].t_stop.magnitude - sts[0].t_start.magnitude) / t_res)\n",
    "    return t\n",
    "\n",
    "def get_st(dsv, s_res=None, t_res=None):\n",
    "    \"\"\"\n",
    "    Retrieve positions and spike times for all neurons in DataStoreView\n",
    "    \"\"\"\n",
    "    posx,posy = get_s(dsv,s_res)\n",
    "    t = get_t(dsv,t_res)\n",
    "    return posx, posy, t\n",
    "\n",
    "def gen_spike_video(dsv, s_res=None, t_res=None, min_t=0, max_t=sys.maxsize):\n",
    "    \"\"\"\n",
    "    Create a 'video' (3D array - space x space x time) from recorded spikes.\n",
    "    s_res and t_res define the bin size into which the spikes are pooled\n",
    "    The maximum space and time dimensions are defined by neuron coordinates\n",
    "    and maximum time either by max_t or the maximum spike time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dsv : DataStoreView\n",
    "             DataStoreView containing a single recording\n",
    "    s_res : int (um)\n",
    "             Spatial bin size\n",
    "    t_res : int (ms)\n",
    "             Time bin size    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Enforce that results can only come from a single sheet\n",
    "    assert len(dsv.sheets()) == 1\n",
    "    \n",
    "    # Get neuron positions and spike times for each neuron\n",
    "    posx, posy, t = get_st(dsv, s_res, t_res)\n",
    "    \n",
    "    # Filter out spike times < min_t and > max_t\n",
    "    min_t=min_t//t_res\n",
    "    max_t=max_t//t_res\n",
    "    for i in range(len(t)):\n",
    "        t[i] = [st-min_t for st in t[i] if st >= min_t and st < max_t]\n",
    "\n",
    "    # Create 3D spike histogram\n",
    "    A = np.zeros((max(posx)+1, max(posy)+1,max([v for l in t for v in l])+1))\n",
    "    for i in range(len(t)):\n",
    "        for st in t[i]:\n",
    "            A[posx[i],posy[i],st] += 1\n",
    "\n",
    "    # Output will be the mean firing rate (Hz) in each bin       \n",
    "    A = A / t_res * 1000\n",
    "    return A\n",
    "\n",
    "# Plot the mean activity across the entire recording, each stimulus separately\n",
    "#image_paths = retrieve_ds_param_values(dsv, \"image_path\")\n",
    "#for im_path in image_paths:\n",
    "#    print(\"Image path:\",im_path)\n",
    "#    dsv2 = fetch_ds_dsv(dsv,{\"image_path\": im_path})\n",
    "#    A = gen_spike_video(dsv2, s_res=30, t_res=5)\n",
    "#    # Plot the mean activity across the entire recording \n",
    "#    plt.imshow(A.mean(axis=2))\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69367556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
